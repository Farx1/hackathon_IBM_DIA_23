# ğŸ”§ FonctionnalitÃ©s AvancÃ©es du Projet

Ce document prÃ©sente les fonctionnalitÃ©s avancÃ©es implÃ©mentÃ©es dans Track Sustainability.

## ğŸ“‹ Table des matiÃ¨res

1. [SystÃ¨me de DÃ©duplication Intelligent](#systÃ¨me-de-dÃ©duplication-intelligent)
2. [Affichage Adaptatif des Valeurs](#affichage-adaptatif-des-valeurs)
3. [Dashboard Multi-Datasets](#dashboard-multi-datasets)

---

## ğŸ”§ SystÃ¨me de DÃ©duplication Intelligent

### FonctionnalitÃ©s

#### 1. Double SystÃ¨me de DÃ©duplication

Le systÃ¨me utilise deux niveaux de dÃ©duplication pour garantir l'exactitude des statistiques :

- **MÃ©moire** (`processedMessages`) : Pour les performances (rapide)
- **Persistant** (`processedMessagesPersistent`) : StockÃ© dans `chrome.storage.local`
- Les messages sont sauvegardÃ©s par conversation et persistent mÃªme aprÃ¨s rechargement

#### 2. Hash Stable BasÃ© sur le Contenu

**ImplÃ©mentation** :
```javascript
const hash = `${conversationId}-${role}-${contentHash}-${messageId}`; // âœ… Stable
```

**Avantages** :
- Le mÃªme message a toujours le mÃªme hash
- Fonctionne mÃªme si le message est dÃ©placÃ© dans le DOM lors du scroll
- Inclut l'ID de conversation pour Ã©viter les collisions

#### 3. ID de Conversation Unique

Chaque conversation a un ID unique basÃ© sur :
- L'URL de la conversation (si disponible)
- Sinon, un hash de l'URL complÃ¨te

**Avantages** :
- Les messages sont isolÃ©s par conversation
- Ã‰vite les collisions entre diffÃ©rentes conversations
- Permet de charger les messages dÃ©jÃ  traitÃ©s pour une conversation spÃ©cifique

#### 4. VÃ©rification ComplÃ¨te

Le systÃ¨me vÃ©rifie TOUS les messages visibles :
```javascript
for (const messageEl of messages) { // âœ… VÃ©rifie tous les messages
  if (!processedMessages.has(hash) && !processedMessagesPersistent.has(hash)) {
    // Nouveau message
  }
}
```

**Avantages** :
- DÃ©tecte correctement les nouveaux messages mÃªme lors du scroll
- Ignore les messages dÃ©jÃ  traitÃ©s, mÃªme s'ils rÃ©apparaissent

#### 5. DÃ©tection des Changements d'URL

DÃ©tection automatique des changements d'URL (nouvelle conversation) :
- RÃ©initialise les compteurs
- Charge les messages dÃ©jÃ  traitÃ©s pour la nouvelle conversation
- Fonctionne avec les Single Page Applications (SPAs)

#### 6. Nettoyage Automatique

Nettoyage automatique toutes les 5 minutes :
- Garde seulement les 10 conversations les plus rÃ©centes
- Limite Ã  1000 messages par conversation
- Ã‰vite le stockage excessif

### ğŸ“Š RÃ©sultat

| Aspect | FonctionnalitÃ© |
|--------|----------------|
| **Scroll** | âœ… Messages ignorÃ©s automatiquement |
| **DÃ©duplication** | âœ… MÃ©moire + Persistant |
| **Hash** | âœ… BasÃ© sur contenu (stable) |
| **Conversation** | âœ… ID unique par conversation |
| **PrÃ©cision** | âœ… Comptage unique garanti |

### ğŸ“ Fichiers ModifiÃ©s

- âœ… `client/public/content.js` : 
  - SystÃ¨me de dÃ©duplication persistant
  - Hash stable basÃ© sur contenu
  - ID de conversation
  - DÃ©tection changements d'URL
  - Nettoyage automatique

---

## ğŸ”§ Affichage Adaptatif des Valeurs

### FonctionnalitÃ©s

#### 1. Affichage COâ‚‚ Intelligent

**Fonction `formatCO2()`** :
```javascript
function formatCO2(co2Grams) {
  if (co2Grams === 0 || isNaN(co2Grams)) {
    return '0.0000';
  }
  
  // Si trÃ¨s petit (< 0.0001), utiliser la notation scientifique
  if (co2Grams < 0.0001) {
    return co2Grams.toExponential(2); // Ex: 6.87e-5
  }
  
  // Sinon, afficher avec 4 dÃ©cimales
  return co2Grams.toFixed(4);
}
```

**RÃ©sultat** :
- âœ… Petites valeurs affichÃ©es en notation scientifique (ex: `6.87e-5 g`)
- âœ… Valeurs normales affichÃ©es avec 4 dÃ©cimales (ex: `0.0012 g`)

#### 2. Estimation de Tokens AmÃ©liorÃ©e

**FonctionnalitÃ©s** :
- âœ… DÃ©tection du markdown/code (facteur Ã—1.3)
- âœ… Formule prÃ©cise : `0.75 tokens/mot`
- âœ… Poids adaptatif selon la longueur du texte
- âœ… Meilleure gestion des textes longs

**ImplÃ©mentation** :
```javascript
// DÃ©tection markdown/code
const isCodeOrMarkdown = /[#*`{}[\]()]/.test(text) || ...;
const codeFactor = isCodeOrMarkdown ? 1.3 : 1.0;

// Formule amÃ©liorÃ©e
tokensFromWords = words * 0.75 * codeFactor;
tokensFromChars = chars / 4;

// Poids adaptatif
const weight = chars > 500 ? 0.7 : 0.6;
estimatedTokens = (tokensFromWords * weight + tokensFromChars * (1 - weight));
```

**RÃ©sultat** :
- âœ… Estimation prÃ©cise pour les textes longs
- âœ… Meilleure prise en compte du markdown/code
- âœ… Tokens proches de la rÃ©alitÃ©

#### 3. Ã‰quivalences COâ‚‚ Adaptatives

**Seuils intelligents** :
- âœ… **< 0.00001 g** : Affiche "-"
- âœ… **< 0.0001 g** : Affiche en microgrammes (Âµg)
- âœ… **< 0.001 g** : Affiche en secondes de respiration
- âœ… **< 0.01 g** : Affiche en milligrammes (mg)
- âœ… **< 0.1 g** : Affiche en recherches Google
- âœ… **< 1 g** : Affiche en emails
- âœ… **< 10 g** : Affiche en km en voiture
- âœ… **â‰¥ 10 g** : Affiche en arbres nÃ©cessaires

### ğŸ“ Fichiers ModifiÃ©s

- âœ… `client/public/popup.js` :
  - Fonction `formatCO2()` ajoutÃ©e
  - AmÃ©lioration de `updateEquivalence()`
  
- âœ… `client/public/content.js` :
  - AmÃ©lioration de `estimateTokens()`
  - Logs de diagnostic ajoutÃ©s

---

## ğŸ”§ Dashboard Multi-Datasets

### FonctionnalitÃ©s

#### 1. Chargement Multi-Datasets

**Fonctionnement** :
- âœ… Recherche automatique de tous les datasets contenant "llm-inference"
- âœ… Chargement sÃ©quentiel de chaque dataset
- âœ… Combinaison de toutes les donnÃ©es
- âœ… Normalisation des colonnes
- âœ… Gestion robuste (continue mÃªme si un dataset est temporairement indisponible)

**Logs** :
```
ğŸ“Š Chargement de 3 datasets...
âœ“ Dataset "alpaca_gemma_2b_laptop2" chargÃ©: 1250 lignes
âœ“ Dataset "alpaca_llama3_8b_workstation" chargÃ©: 2100 lignes
âœ“ Dataset "code_feedback_codellama_7b_server" chargÃ©: 1800 lignes
âœ“ Total: 5150 mesures chargÃ©es depuis 3 datasets
```

#### 2. Normalisation des Colonnes

**Colonnes supportÃ©es** :

| Colonne NormalisÃ©e | Variantes AcceptÃ©es |
|-------------------|---------------------|
| `model_name` | `model_name`, `model`, `Model` |
| `hardware_type` | `hardware_type`, `hardware`, `Hardware`, `type` |
| `prompt_token_length` | `prompt_token_length`, `prompt_tokens`, `Prompt Tokens` |
| `response_token_length` | `response_token_length`, `response_tokens`, `Response Tokens` |
| `energy_consumption_llm_total` | `energy_consumption_llm_total`, `energy_total`, `Energy Total`, `energy` |
| `energy_consumption_llm_cpu` | `energy_consumption_llm_cpu`, `cpu_energy` |
| `energy_consumption_llm_gpu` | `energy_consumption_llm_gpu`, `gpu_energy` |

#### 3. Liste des Datasets

**Fonction** : `listDatasets()` dans le dashboard
- Affiche tous les datasets llm-inference trouvÃ©s dans Watsonx
- Montre l'ID, le nom et le type de chaque dataset
- Permet de vÃ©rifier que les datasets sont bien importÃ©s

**Utilisation** :
1. Aller dans l'onglet "âš™ï¸ Configuration"
2. Cliquer sur "ğŸ“‹ Lister les Datasets Disponibles"
3. Voir la liste des datasets trouvÃ©s

### Structure du Dataset

D'aprÃ¨s Hugging Face, le dataset comprend :

- **ModÃ¨les** : Llama 2, LLaMA 3 (7B, 8B, 70B), CodeLlama, Gemma
- **Hardware** : Workstation, Laptops (2 types), Server
- **Prompt Datasets** : Alpaca, Code-Feedback
- **Total** : ~78,728 mesures, 80 variables, 15 configurations

### AmÃ©liorations Techniques

#### Parser CSV AmÃ©liorÃ©

**FonctionnalitÃ©s** :
- âœ… Parse correctement les valeurs avec guillemets
- âœ… GÃ¨re les colonnes manquantes
- âœ… Compatible avec tous les formats du dataset

#### Normalisation des Colonnes

**FonctionnalitÃ©s** :
- âœ… Mapping intelligent des variantes
- âœ… Gestion des colonnes manquantes
- âœ… CompatibilitÃ© avec tous les formats du dataset

#### Chargement Robuste

**FonctionnalitÃ©s** :
- âœ… Recherche de tous les datasets
- âœ… Combinaison automatique
- âœ… Continue mÃªme si un dataset Ã©choue
- âœ… Logs dÃ©taillÃ©s

---

## ğŸ“Š RÃ©sultats

### Avant les amÃ©liorations
```
- DÃ©duplication : Aucune
- Affichage COâ‚‚ : Format fixe
- Tokens : Estimation basique
- Datasets : Support d'un seul
```

### AprÃ¨s les amÃ©liorations
```
- DÃ©duplication : SystÃ¨me intelligent persistant âœ…
- Affichage COâ‚‚ : Format adaptatif (notation scientifique si nÃ©cessaire) âœ…
- Tokens : Estimation amÃ©liorÃ©e avec dÃ©tection code/markdown âœ…
- Datasets : Support multi-datasets avec normalisation automatique âœ…
```

---

âœ… **Toutes les fonctionnalitÃ©s avancÃ©es sont implÃ©mentÃ©es et opÃ©rationnelles.**
