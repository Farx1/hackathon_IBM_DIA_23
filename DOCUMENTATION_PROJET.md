# ğŸ“Š Documentation du Projet Track Sustainability

Ce document regroupe les informations gÃ©nÃ©rales sur le projet, son Ã©valuation et son rÃ©sumÃ© exÃ©cutif.

## ğŸ“‹ Table des matiÃ¨res

1. [RÃ©sumÃ© ExÃ©cutif](#rÃ©sumÃ©-exÃ©cutif)
2. [RÃ©sumÃ© du Projet](#rÃ©sumÃ©-du-projet)
3. [Ã‰valuation du Projet](#Ã©valuation-du-projet)
4. [Modifications EffectuÃ©es](#modifications-effectuÃ©es)

---

## ğŸŒ± RÃ©sumÃ© ExÃ©cutif

### Projet

Extension Chrome pour estimer et visualiser l'impact carbone (COâ‚‚) des requÃªtes envoyÃ©es aux modÃ¨les de langage (LLM).

### RÃ©sultats clÃ©s

#### ModÃ¨le ML
- **Performance** : RÂ² = 0.984 (98.4% de variance expliquÃ©e)
- **Algorithme** : Gradient Boosting
- **Dataset** : 78,728 mesures rÃ©elles de consommation Ã©nergÃ©tique
- **Features principales** : Longueur de rÃ©ponse (47%), Total tokens (26%), Taille du modÃ¨le (20%)

#### Consommation Ã©nergÃ©tique

| ModÃ¨le | Ã‰nergie/token | Ratio vs 7B |
|--------|---------------|-------------|
| 2B (Gemma) | 0.000000189 J | 0.4Ã— |
| 7B (LLaMA 3) | 0.000000460 J | 1Ã— |
| 70B (GPT-4) | 0.000007753 J | 17Ã— |

**Insight** : GPT-4 (70B) consomme **17Ã— plus** d'Ã©nergie que GPT-3.5 (7B) pour la mÃªme rÃ©ponse.

#### Facteurs COâ‚‚

| Pays | IntensitÃ© (gCOâ‚‚/kWh) | Mix |
|------|----------------------|-----|
| ğŸ‡¸ğŸ‡ª SuÃ¨de | 13 | NuclÃ©aire + Hydro |
| ğŸ‡«ğŸ‡· France | 52 | NuclÃ©aire (65%) |
| ğŸ‡ºğŸ‡¸ Ã‰tats-Unis | 369 | Mix |
| ğŸŒ Moyenne mondiale | 480 | Mix |
| ğŸ‡¨ğŸ‡³ Chine | 581 | Charbon (60%) |
| ğŸ‡µğŸ‡± Pologne | 652 | Charbon (70%) |

---

## ğŸ“Š RÃ©sumÃ© du Projet

### Vue d'ensemble

**Track Sustainability** est une extension Chrome qui estime et visualise l'impact carbone (COâ‚‚) des requÃªtes envoyÃ©es aux modÃ¨les de langage (LLM). Le projet combine machine learning, analyse de donnÃ©es et dÃ©veloppement web pour sensibiliser aux impacts environnementaux de l'IA.

### Objectifs atteints

âœ… Analyse complÃ¨te du dataset LLM energy consumption (78,728 mesures)
âœ… Construction d'un modÃ¨le prÃ©dictif performant (RÂ² = 0.984)
âœ… DÃ©veloppement d'une extension Chrome fonctionnelle
âœ… DÃ©tection automatique de ChatGPT, Claude et Gemini
âœ… SystÃ¨me de conversion COâ‚‚ avec 30+ pays
âœ… Interface utilisateur intuitive et responsive
âœ… Documentation complÃ¨te
âœ… IntÃ©gration Watsonx pour prÃ©dictions avancÃ©es

### RÃ©sultats du modÃ¨le ML

#### Performance

| MÃ©trique | Valeur |
|----------|--------|
| RÂ² Score | 0.9841 |
| MAE | 0.000014 J |
| MSE | 5.01e-09 JÂ² |
| Algorithme | Gradient Boosting |
| Features | 7 |
| Samples (train) | 62,982 |
| Samples (test) | 15,746 |

#### Features Importantes

1. **response_token_length** (47%) : Longueur de la rÃ©ponse en tokens
2. **total_tokens** (26%) : Total des tokens (prompt + rÃ©ponse)
3. **model_size** (20%) : Taille du modÃ¨le (2B, 7B, 70B)
4. **hardware_type** (5%) : Type de hardware
5. **prompt_token_length** (2%) : Longueur du prompt

### Technologies utilisÃ©es

- **Machine Learning** : scikit-learn (Gradient Boosting)
- **Extension Chrome** : Manifest V3, Content Scripts, Service Workers
- **Visualisation** : Chart.js
- **IntÃ©gration** : IBM Watsonx
- **Backend** : Node.js, Express.js

---

## ğŸ“Š Ã‰valuation du Projet

### Objectifs Initiaux vs RÃ©alisations

#### 1. Analyser la consommation Ã©nergÃ©tique d'un modÃ¨le open-source

**Statut** : âœ… **COMPLET**
- Dataset analysÃ© : 78,728 mesures (vs 5,200 demandÃ©es)
- 7 modÃ¨les analysÃ©s (LLaMA, Gemma, CodeLlama)
- 4 types de hardware analysÃ©s

#### 2. Construire un modÃ¨le prÃ©dictif estimant l'Ã©nergie par token/requÃªte

**Statut** : âœ… **COMPLET**
- ModÃ¨le Gradient Boosting avec RÂ² = 0.984
- Performance supÃ©rieure aux attentes
- Export en JavaScript pour l'extension

#### 3. Convertir l'Ã©nergie en COâ‚‚e selon le mix Ã©nergÃ©tique

**Statut** : âœ… **COMPLET**
- 30+ pays disponibles (vs demandÃ©)
- Facteurs d'Ã©mission basÃ©s sur Ember Global Electricity Review 2024
- Conversion automatique en temps rÃ©el

#### 4. DÃ©velopper une interface interactive (extension Chrome)

**Statut** : âœ… **COMPLET**
- Extension Chrome fonctionnelle
- Interface moderne et intuitive
- DÃ©tection automatique ChatGPT, Claude, Gemini
- Dashboard complet avec graphiques

### Points Forts

1. **ModÃ¨le ML performant** : RÂ² = 0.984 (excellent)
2. **Dataset complet** : 78,728 mesures (vs 5,200 demandÃ©es)
3. **Interface utilisateur** : Moderne, intuitive, responsive
4. **Documentation** : ComplÃ¨te et dÃ©taillÃ©e
5. **IntÃ©gration Watsonx** : PrÃ©dictions avancÃ©es avec modÃ¨le dÃ©ployÃ©
6. **PrÃ©cision des tokens** : Interception rÃ©seau pour donnÃ©es API rÃ©elles
7. **Interception rÃ©seau** : Support multi-plateformes (ChatGPT, Claude, Gemini)
8. **Performance** : Chargement optimisÃ© des donnÃ©es
9. **Robustesse** : SystÃ¨me de dÃ©duplication et gestion robuste des cas limites

---

## ğŸ“ Modifications EffectuÃ©es

### Objectif

AmÃ©liorer la capacitÃ© de l'extension Ã  scanner et analyser les messages des LLM (ChatGPT, Claude, Gemini) pour calculer prÃ©cisÃ©ment le facteur de CO2 gÃ©nÃ©rÃ© par les prompts.

### Modifications RÃ©alisÃ©es

#### 1. Ajout de l'Interception RÃ©seau â­ (Critique)

**Fichier crÃ©Ã©** : `client/public/network-interceptor.js`

**FonctionnalitÃ©** : Intercepte les requÃªtes rÃ©seau (`fetch` et `XMLHttpRequest`) pour rÃ©cupÃ©rer les **vraies donnÃ©es** depuis les APIs des plateformes :

- âœ… **ModÃ¨le rÃ©el utilisÃ©** (gpt-4, claude-3.5-sonnet, etc.)
- âœ… **Tokens exacts** (prompt_tokens, completion_tokens)
- âœ… **Contenu des messages** (pour validation)

**Avantages** :
- DonnÃ©es **100% prÃ©cises** (pas d'estimation)
- DÃ©tection automatique du **modÃ¨le rÃ©el**
- Fonctionne mÃªme si la structure DOM change

#### 2. AmÃ©lioration de l'Extraction du Texte

**Fichier modifiÃ©** : `client/public/content.js`

**AmÃ©liorations** :
- âœ… Extraction rÃ©cursive complÃ¨te
- âœ… PrÃ©servation des blocs de code
- âœ… Gestion des messages multi-parties
- âœ… Nettoyage intelligent

#### 3. SystÃ¨me de DÃ©duplication

**Fichier modifiÃ©** : `client/public/content.js`

**FonctionnalitÃ©s** :
- âœ… Hash stable basÃ© sur le contenu
- âœ… Stockage persistant dans `chrome.storage.local`
- âœ… Isolation par conversation
- âœ… Nettoyage automatique

#### 4. IntÃ©gration Watsonx

**Fichiers crÃ©Ã©s** :
- `client/public/watsonx-config.js`
- `client/public/watsonx-service.js`

**FonctionnalitÃ©s** :
- âœ… Configuration Watsonx dans le dashboard
- âœ… PrÃ©dictions avec modÃ¨le dÃ©ployÃ©
- âœ… Fallback vers modÃ¨les locaux
- âœ… Serveur local pour sÃ©curitÃ©

---

## ğŸ“ˆ Impact et RÃ©sultats

### Consommation Ã©nergÃ©tique par modÃ¨le

| Taille | Ã‰nergie/token | Exemple |
|--------|---------------|---------|
| 2B | 0.000000189 J | Gemma 2B |
| 7B | 0.000000460 J | LLaMA 3 8B, Mistral 7B |
| 70B | 0.000007753 J | GPT-4, Claude 3 Opus |

**Note** : Un modÃ¨le 70B consomme environ **40Ã— plus** d'Ã©nergie par token qu'un modÃ¨le 7B.

### Ã‰quivalences COâ‚‚

Pour 1000 requÃªtes Ã  GPT-4 (moyenne 500 tokens/rÃ©ponse) :

- **Ã‰nergie** : ~3.9 J
- **COâ‚‚** (mix mondial) : ~0.52 g
- **Ã‰quivalent** : ~2.6 recherches Google

---

## ğŸ“ Contexte AcadÃ©mique

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre d'un projet acadÃ©mique sur la **durabilitÃ© de l'IA** :

- **Objectif** : Sensibiliser aux impacts environnementaux des LLM
- **Dataset** : Hugging Face - ejhusom/llm-inference-energy-consumption
- **Expert** : Hernan Carrillo (Data & AI Scientist, Capgemini)

## ğŸ‘¥ Ã‰quipe

**ğŸŒ± Track Sustainability Team**

- **Jules Sayad-Barth**
- **Hugo Robin**
- **Leo Demelle**
- **Ghadi Salameh**
- **Maria Katibi**

---

## ğŸ“š RÃ©fÃ©rences

1. **Dataset** : [LLM Inference Energy Consumption](https://huggingface.co/datasets/ejhusom/llm-inference-energy-consumption)
2. **Paper** : "The Price of Prompting: Profiling Energy Use in Large Language Models Inference" (2024)
3. **Ember** : [Global Electricity Review 2024](https://ember-energy.org/latest-insights/global-electricity-review-2024/)
4. **IEA** : [Emissions Factors 2024](https://www.iea.org/data-and-statistics/data-product/emissions-factors-2024)
5. **IBM Watsonx** : [Documentation Watsonx](https://www.ibm.com/products/watsonx-ai)

---

âœ… **Le projet Track Sustainability est complet, fonctionnel et prÃªt pour utilisation et dÃ©monstration.**

