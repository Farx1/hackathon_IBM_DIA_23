# ğŸ“Š Track Sustainability - RÃ©sumÃ© du Projet

## Vue d'ensemble

**Track Sustainability** est une extension Chrome qui estime et visualise l'impact carbone (COâ‚‚) des requÃªtes envoyÃ©es aux modÃ¨les de langage (LLM). Le projet combine machine learning, analyse de donnÃ©es et dÃ©veloppement web pour sensibiliser aux impacts environnementaux de l'IA.

## ğŸ¯ Objectifs atteints

âœ… Analyse complÃ¨te du dataset LLM energy consumption (78,728 mesures)
âœ… Construction d'un modÃ¨le prÃ©dictif performant (RÂ² = 0.984)
âœ… DÃ©veloppement d'une extension Chrome fonctionnelle
âœ… DÃ©tection automatique de ChatGPT, Claude et Gemini
âœ… SystÃ¨me de conversion COâ‚‚ avec 30+ pays
âœ… Interface utilisateur intuitive et responsive
âœ… Documentation complÃ¨te

## ğŸ“ˆ RÃ©sultats du modÃ¨le ML

### Performance

| MÃ©trique | Valeur |
|----------|--------|
| RÂ² Score | 0.9841 |
| MAE | 0.000014 J |
| MSE | 5.01e-09 JÂ² |
| Algorithme | Gradient Boosting |
| Features | 7 |
| Samples (train) | 62,982 |
| Samples (test) | 15,746 |

### Top 3 Features

1. **response_token_length** : 46.81% d'importance
2. **total_tokens** : 25.53% d'importance
3. **model_size** : 20.17% d'importance

### Consommation Ã©nergÃ©tique par taille

| Taille | Ã‰nergie/token | MÃ©diane | Exemple |
|--------|---------------|---------|---------|
| 2B | 1.89e-07 J | 5.14e-05 J | Gemma 2B |
| 7B | 4.60e-07 J | 1.38e-04 J | LLaMA 3 8B |
| 70B | 7.75e-06 J | 1.95e-03 J | GPT-4, Claude 3 |

**Insight clÃ©** : Un modÃ¨le 70B consomme **~40Ã— plus** d'Ã©nergie par token qu'un modÃ¨le 7B.

## ğŸŒ Facteurs d'Ã©mission COâ‚‚

### Pays avec le mix le plus propre

| Pays | IntensitÃ© (gCOâ‚‚/kWh) | Mix dominant |
|------|----------------------|--------------|
| ğŸ‡¸ğŸ‡ª SuÃ¨de | 13 | Hydro + NuclÃ©aire |
| ğŸ‡³ğŸ‡´ NorvÃ¨ge | 18 | Hydro (92%) |
| ğŸ‡¨ğŸ‡­ Suisse | 24 | Hydro + NuclÃ©aire |
| ğŸ‡«ğŸ‡· France | 52 | NuclÃ©aire (65%) |

### Pays avec le mix le plus carbonÃ©

| Pays | IntensitÃ© (gCOâ‚‚/kWh) | Mix dominant |
|------|----------------------|--------------|
| ğŸ‡¿ğŸ‡¦ Afrique du Sud | 750 | Charbon (86%) |
| ğŸ‡µğŸ‡± Pologne | 652 | Charbon (70%) |
| ğŸ‡®ğŸ‡³ Inde | 632 | Charbon (75%) |
| ğŸ‡¨ğŸ‡³ Chine | 581 | Charbon (62%) |

**Moyenne mondiale** : 480 gCOâ‚‚/kWh

## ğŸ’» Architecture technique

### Extension Chrome

```
Structure Manifest V3
â”œâ”€â”€ popup.html/js       â†’ Interface utilisateur
â”œâ”€â”€ content.js          â†’ DÃ©tection conversations
â”œâ”€â”€ background.js       â†’ Service worker (calculs)
â”œâ”€â”€ predictor.js        â†’ ModÃ¨le ML simplifiÃ©
â””â”€â”€ data/
    â”œâ”€â”€ model_simplified.json
    â””â”€â”€ carbon_intensity.json
```

### Pipeline ML

```
Dataset (158 MB)
    â†“
Nettoyage & EDA
    â†“
Feature Engineering
    â†“
EntraÃ®nement (4 modÃ¨les)
    â†“
SÃ©lection (Gradient Boosting)
    â†“
Export JavaScript
    â†“
IntÃ©gration Extension
```

## ğŸ“Š Statistiques du dataset

- **Lignes** : 78,728 mesures
- **Colonnes** : 80 variables
- **ModÃ¨les** : 7 (Gemma 2B/7B, LLaMA 3, CodeLlama)
- **Hardware** : 4 types (laptop, workstation, server)
- **Datasets** : 2 (Alpaca, Code-Feedback)
- **Taille** : 158 MB (15 fichiers CSV)

## ğŸ¨ Interface utilisateur

### FonctionnalitÃ©s

- âœ… Statut de dÃ©tection en temps rÃ©el
- âœ… Statistiques session actuelle
- âœ… Statistiques cumulÃ©es
- âœ… Ã‰quivalences COâ‚‚ concrÃ¨tes
- âœ… SÃ©lecteur de mix Ã©nergÃ©tique
- âœ… Bouton de rÃ©initialisation
- âœ… Design moderne (gradient violet)

### Ã‰quivalences affichÃ©es

- < 1g : Minutes de respiration
- < 100g : Recherches Google
- < 1kg : Emails envoyÃ©s
- < 10kg : Km en voiture
- > 10kg : Arbres nÃ©cessaires/an

## ğŸ”¬ MÃ©thodologie scientifique

### Sources de donnÃ©es

1. **Dataset principal** : Hugging Face - ejhusom/llm-inference-energy-consumption
2. **Facteurs COâ‚‚** : Ember Global Electricity Review 2024, IEA
3. **Paper de rÃ©fÃ©rence** : "The Price of Prompting" (2024)

### Formule de calcul

```
Ã‰nergie (J) = Base + (Prompt Ã— 0.3 Ã— E/token) + (Response Ã— 1.0 Ã— E/token)

COâ‚‚ (g) = (Ã‰nergie_J / 3,600,000) Ã— IntensitÃ©_carbone
```

### Validation

- **Cross-validation** : 5-fold
- **Test set** : 20% des donnÃ©es
- **MÃ©triques** : RÂ², MAE, MSE
- **Comparaison** : 4 algorithmes testÃ©s

## ğŸ“¦ Livrables

### Code source

- âœ… Scripts Python d'analyse (4 fichiers)
- âœ… Extension Chrome complÃ¨te
- âœ… ModÃ¨le ML entraÃ®nÃ© (.pkl)
- âœ… ModÃ¨le simplifiÃ© (.json)
- âœ… DonnÃ©es COâ‚‚ (30+ pays)

### Documentation

- âœ… README.md (complet, 300+ lignes)
- âœ… INSTALLATION.md (guide pas Ã  pas)
- âœ… PROJECT_SUMMARY.md (ce fichier)
- âœ… Code commentÃ© et structurÃ©

### Visualisations

- âœ… Distribution de l'Ã©nergie
- âœ… Consommation par modÃ¨le
- âœ… Tokens vs Ã‰nergie
- âœ… Matrice de corrÃ©lation
- âœ… Importance des features
- âœ… Analyse des prÃ©dictions

### Package

- âœ… Extension ZIP (41 KB)
- âœ… IcÃ´nes PNG (16, 48, 128 px)
- âœ… Manifest V3 valide

## ğŸ“ Contexte acadÃ©mique

**Projet** : Track Sustainability - Estimation et Simulation du COâ‚‚ Impact des LLM
**Objectif** : Concevoir une solution complÃ¨te combinant IA et interface pour estimer l'empreinte carbone des requÃªtes LLM
**Expert** : Hernan Carrillo (Data & AI Scientist, Capgemini)
**Dataset** : 5,200 lignes, 80 variables, 15 configurations

## ğŸš€ Utilisation

### Installation

1. TÃ©lÃ©charger l'extension
2. Ouvrir `chrome://extensions/`
3. Activer le mode dÃ©veloppeur
4. Charger l'extension non empaquetÃ©e

### Test

1. Aller sur chat.openai.com
2. Envoyer un message
3. Ouvrir le popup de l'extension
4. Voir l'impact COâ‚‚ en temps rÃ©el

## ğŸ“ˆ Exemples de rÃ©sultats

### Exemple 1 : RequÃªte simple Ã  GPT-4

- **Prompt** : "Bonjour, comment vas-tu ?" (50 tokens)
- **RÃ©ponse** : 200 tokens
- **Ã‰nergie** : 0.00194 J
- **COâ‚‚ (France)** : 0.000028 g
- **COâ‚‚ (Chine)** : 0.000313 g

### Exemple 2 : Conversation longue (10 Ã©changes)

- **Total tokens** : 5,000
- **Ã‰nergie** : 0.0388 J
- **COâ‚‚ (mix mondial)** : 0.0052 g
- **Ã‰quivalent** : ~0.026 recherches Google

### Exemple 3 : Comparaison modÃ¨les

| ModÃ¨le | Tokens | Ã‰nergie (J) | COâ‚‚ (g, mondial) |
|--------|--------|-------------|------------------|
| GPT-3.5 (7B) | 500 | 0.00023 | 0.000031 |
| GPT-4 (70B) | 500 | 0.00388 | 0.000517 |

**Ratio** : GPT-4 consomme **~17Ã— plus** que GPT-3.5 pour la mÃªme rÃ©ponse.

## ğŸ”® Perspectives d'amÃ©lioration

### Court terme

- [ ] Support de plus de plateformes (Perplexity, HuggingChat)
- [ ] Graphiques d'historique
- [ ] Export des donnÃ©es (CSV)
- [ ] Mode sombre

### Moyen terme

- [ ] Comparaison entre modÃ¨les
- [ ] Suggestions d'optimisation
- [ ] Badge avec impact en temps rÃ©el
- [ ] API publique

### Long terme

- [ ] ModÃ¨le ML plus prÃ©cis (deep learning)
- [ ] IntÃ©gration hardware rÃ©el
- [ ] Support mobile (Firefox, Safari)
- [ ] Dashboard web complet

## ğŸ“š RÃ©fÃ©rences

1. Husom et al. (2024). "The Price of Prompting: Profiling Energy Use in Large Language Models Inference"
2. Ember (2024). "Global Electricity Review 2024"
3. IEA (2024). "Emissions Factors 2024"
4. Our World in Data. "Carbon Intensity of Electricity Generation"

## ğŸ† Points forts du projet

1. **DonnÃ©es rÃ©elles** : BasÃ© sur 78k+ mesures rÃ©elles
2. **ModÃ¨le performant** : RÂ² = 0.984
3. **Interface intuitive** : Design moderne et responsive
4. **DÃ©tection automatique** : Fonctionne sans configuration
5. **Personnalisable** : 30+ pays disponibles
6. **Documentation complÃ¨te** : README, guides, commentaires
7. **Open source** : Code clair et rÃ©utilisable

## âš ï¸ Limitations

1. **Estimations** : BasÃ©es sur des modÃ¨les statistiques
2. **DÃ©tection heuristique** : Peut Ã©chouer si DOM change
3. **ModÃ¨les propriÃ©taires** : ExtrapolÃ©s depuis open-source
4. **Pas de hardware rÃ©el** : Calculs thÃ©oriques

## ğŸ“§ Contact

**Expert** : Hernan Carrillo
**Email** : hernan-camilo.carrillo-lindado@capgemini.com

---

**Projet rÃ©alisÃ© avec ğŸ’š pour un futur plus durable**
