# Configuration du Serveur Local

Ce guide explique comment configurer le serveur local pour les pr√©dictions ML avec Watsonx.

## Pr√©requis

- Node.js install√©
- Un compte IBM Cloud avec acc√®s √† Watsonx
- Un mod√®le ML d√©ploy√© sur Watsonx (Deployment ID: `hckt23`)

## Configuration

### 1. Cr√©er le fichier `.env`

Copiez le fichier `.env.example` en `.env` :

```bash
cp .env.example .env
```

### 2. Remplir les variables d'environnement

Ouvrez le fichier `.env` et remplissez les valeurs :

```env
# IBM Watsonx Configuration
IBM_API_KEY=cpd-apikey-VOTRE_CLE_API_ICI
IBM_PROJECT_ID=votre-project-id-ici
IBM_DEPLOYMENT_ID=hckt23
IBM_REGION=eu-de
PORT=3000
```

**O√π trouver ces valeurs :**

- **IBM_API_KEY** : Dans IBM Cloud, allez dans "G√©rer" > "Cl√©s d'acc√®s" > Cr√©ez une nouvelle cl√© API
- **IBM_PROJECT_ID** : Dans Watsonx, ouvrez votre projet et copiez l'ID depuis l'URL ou les param√®tres
- **IBM_DEPLOYMENT_ID** : L'ID du d√©ploiement de votre mod√®le (par d√©faut: `hckt23`)
- **IBM_REGION** : La r√©gion de votre instance Watsonx (`eu-de` pour Frankfurt, `us-south` pour Dallas, etc.)

### 3. Installer les d√©pendances

```bash
npm install
# ou
pnpm install
```

### 4. D√©marrer le serveur

**Mode d√©veloppement :**
```bash
npm run dev
```

**Mode production :**
```bash
npm run build
npm start
```

Le serveur d√©marre sur `http://localhost:3000` par d√©faut.

## Endpoints API

Le serveur expose les endpoints suivants :

- `GET /api/health` - V√©rifier l'√©tat du serveur et la configuration
- `GET /api/test-auth` - Tester l'authentification avec IBM Cloud
- `POST /api/predict` - Faire une pr√©diction unique
- `POST /api/predict-batch` - Faire des pr√©dictions en batch

### Exemple de requ√™te de pr√©diction

```bash
curl -X POST http://localhost:3000/api/predict \
  -H "Content-Type: application/json" \
  -d '{
    "totalDuration": 1234567890,
    "promptTokens": 100,
    "responseTokens": 200,
    "responseDuration": 987654321,
    "wordCount": 150,
    "readingTime": 45.5
  }'
```

### Exemple de r√©ponse

```json
{
  "success": true,
  "energyJoules": 0.00123456,
  "source": "watsonx-deployed"
}
```

## Utilisation avec l'Extension Chrome

Une fois le serveur d√©marr√© :

1. Ouvrez le dashboard de l'extension
2. Allez dans l'onglet "Pr√©dictions ML"
3. S√©lectionnez "üñ•Ô∏è Serveur Local" comme mod√®le de pr√©diction
4. Le statut du serveur s'affichera automatiquement

L'extension appellera automatiquement le serveur local au lieu d'appeler Watsonx directement, ce qui permet de garder les credentials s√©curis√©s dans le fichier `.env`.

## S√©curit√©

‚ö†Ô∏è **Important** : Ne commitez jamais le fichier `.env` dans Git. Il contient des credentials sensibles.

Le fichier `.env` est d√©j√† dans `.gitignore` par d√©faut.

## D√©pannage

### Le serveur ne d√©marre pas

- V√©rifiez que le port 3000 n'est pas d√©j√† utilis√©
- V√©rifiez que toutes les variables d'environnement sont d√©finies dans `.env`
- V√©rifiez les logs pour les erreurs de configuration

### Erreur d'authentification

- V√©rifiez que votre `IBM_API_KEY` est correcte et active
- V√©rifiez que votre `IBM_PROJECT_ID` correspond √† un projet existant
- V√©rifiez que votre `IBM_DEPLOYMENT_ID` correspond √† un d√©ploiement actif

### L'extension ne peut pas se connecter au serveur

- V√©rifiez que le serveur tourne sur `http://localhost:3000`
- V√©rifiez que CORS est activ√© (d√©j√† configur√© par d√©faut)
- V√©rifiez la console du navigateur pour les erreurs

