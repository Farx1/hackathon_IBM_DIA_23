# üîß Corrections Dashboard et Int√©gration Multi-Datasets

## Probl√®mes Identifi√©s et Corrig√©s

### 1. ‚ùå Probl√®me : Configuration non fonctionnelle dans le dashboard

**Cause** : Les scripts `watsonx-service.js` et `watsonx-config.js` n'√©taient pas charg√©s correctement dans le dashboard HTML.

**Solution** :
- ‚úÖ Chargement dynamique des scripts via `loadScript()` dans `dashboard.js`
- ‚úÖ Utilisation de `chrome.runtime.getURL()` pour obtenir les URLs correctes
- ‚úÖ Gestion des erreurs de chargement

### 2. ‚ùå Probl√®me : Support d'un seul dataset

**Cause** : Le code cherchait un seul dataset alors que le [dataset Hugging Face](https://huggingface.co/datasets/ejhusom/llm-inference-energy-consumption) contient plusieurs fichiers CSV avec diff√©rentes configurations.

**Solution** :
- ‚úÖ Fonction `findDatasets()` : Trouve tous les datasets contenant "llm-inference" dans le nom
- ‚úÖ `loadDatasetFromWatsonx()` : Charge et combine automatiquement tous les datasets trouv√©s
- ‚úÖ Normalisation des colonnes : G√®re les diff√©rences entre fichiers CSV
- ‚úÖ Gestion des colonnes manquantes : Le parser CSV g√®re maintenant les fichiers avec des colonnes diff√©rentes

### 3. ‚ùå Probl√®me : Colonnes manquantes/divergentes

**Cause** : D'apr√®s le dataset Hugging Face, certains fichiers CSV ont des colonnes manquantes (`Unnamed: 0.1`, `Unnamed: 0.2`) ou des noms de colonnes diff√©rents.

**Solution** :
- ‚úÖ Fonction `normalizeDatasetColumns()` : Normalise les noms de colonnes entre fichiers
- ‚úÖ Mapping intelligent : D√©tecte les variantes de noms (ex: `model_name` vs `model` vs `Model`)
- ‚úÖ Parser CSV am√©lior√© : G√®re les guillemets et les virgules dans les valeurs
- ‚úÖ Gestion des colonnes manquantes : Les colonnes manquantes sont laiss√©es vides au lieu de causer une erreur

## Nouvelles Fonctionnalit√©s

### 1. üìã Liste des Datasets

**Fonction** : `listDatasets()` dans le dashboard
- Affiche tous les datasets llm-inference trouv√©s dans Watsonx
- Montre l'ID, le nom et le type de chaque dataset
- Permet de v√©rifier que les datasets sont bien import√©s

**Utilisation** :
1. Aller dans l'onglet "‚öôÔ∏è Configuration"
2. Cliquer sur "üìã Lister les Datasets Disponibles"
3. Voir la liste des datasets trouv√©s

### 2. üîÑ Chargement Multi-Datasets

**Fonctionnement** :
- Recherche automatique de tous les datasets contenant "llm-inference"
- Chargement s√©quentiel de chaque dataset
- Combinaison de toutes les donn√©es
- Normalisation des colonnes
- Gestion des erreurs (continue m√™me si un dataset √©choue)

**Logs** :
```
üìä Chargement de 3 datasets...
‚úì Dataset "alpaca_gemma_2b_laptop2" charg√©: 1250 lignes
‚úì Dataset "alpaca_llama3_8b_workstation" charg√©: 2100 lignes
‚úì Dataset "code_feedback_codellama_7b_server" charg√©: 1800 lignes
‚úì Total: 5150 mesures charg√©es depuis 3 datasets
```

### 3. üóÇÔ∏è Normalisation des Colonnes

**Colonnes support√©es** :

| Colonne Normalis√©e | Variantes Accept√©es |
|-------------------|---------------------|
| `model_name` | `model_name`, `model`, `Model` |
| `hardware_type` | `hardware_type`, `hardware`, `Hardware`, `type` |
| `prompt_token_length` | `prompt_token_length`, `prompt_tokens`, `Prompt Tokens` |
| `response_token_length` | `response_token_length`, `response_tokens`, `Response Tokens` |
| `energy_consumption_llm_total` | `energy_consumption_llm_total`, `energy_total`, `Energy Total`, `energy` |
| `energy_consumption_llm_cpu` | `energy_consumption_llm_cpu`, `cpu_energy` |
| `energy_consumption_llm_gpu` | `energy_consumption_llm_gpu`, `gpu_energy` |

## Structure du Dataset

D'apr√®s [Hugging Face](https://huggingface.co/datasets/ejhusom/llm-inference-energy-consumption), le dataset comprend :

### Mod√®les
- **Llama** : LLaMA 2, LLaMA 3 (7B, 8B, 70B)
- **CodeLlama** : CodeLlama 7B, 13B, 34B, 70B
- **Gemma** : Gemma 2B, 7B

### Hardware
- **Workstation**
- **Laptops** (2 types)
- **Server**

### Prompt Datasets
- **Alpaca** : Prompts g√©n√©raux
- **Code-Feedback** : Prompts de code

### Total
- **~78,728 mesures** (selon la documentation)
- **80 variables** par mesure
- **15 configurations** (mod√®les √ó hardware)

## Fichiers CSV du Dataset

Le dataset contient plusieurs fichiers CSV, par exemple :
- `alpaca_gemma_2b_laptop2.csv`
- `alpaca_llama3_8b_workstation.csv`
- `code_feedback_codellama_7b_server.csv`
- Etc.

**Note** : Certains fichiers ont des colonnes manquantes (`Unnamed: 0.1`, `Unnamed: 0.2`), ce qui est maintenant g√©r√© automatiquement.

## Utilisation

### 1. Configuration Initiale

1. **Ouvrir le dashboard** :
   - Clic droit sur l'ic√¥ne extension ‚Üí "Options"
   - Ou depuis le popup : bouton "üìä Ouvrir le Dashboard Analytics"

2. **Aller dans l'onglet "‚öôÔ∏è Configuration"**

3. **Remplir les champs** :
   - API Key
   - API URL (r√©gion)
   - Project ID
   - Nom du Dataset (optionnel, par d√©faut: `llm-inference-energy-consumption`)

4. **Tester la connexion** :
   - Cliquer sur "üîç Tester la Connexion"
   - V√©rifier que √ßa fonctionne

5. **Lister les datasets** :
   - Cliquer sur "üìã Lister les Datasets Disponibles"
   - V√©rifier que tous les datasets sont trouv√©s

6. **Sauvegarder** :
   - Cliquer sur "üíæ Sauvegarder Configuration"

### 2. Utilisation du Dashboard

Une fois configur√©, le dashboard :
- ‚úÖ Charge automatiquement tous les datasets trouv√©s
- ‚úÖ Combine les donn√©es
- ‚úÖ Normalise les colonnes
- ‚úÖ Affiche les statistiques globales
- ‚úÖ Permet les comparaisons par mod√®le, GPU, mix √©nerg√©tique

## Am√©liorations Techniques

### Parser CSV Am√©lior√©

**Avant** :
```javascript
// Simple split par virgule - ne g√®re pas les guillemets
const values = line.split(',');
```

**Apr√®s** :
```javascript
// Parse correctement les valeurs avec guillemets
function parseCSVLine(line) {
  // G√®re les virgules dans les valeurs entre guillemets
  // G√®re les colonnes manquantes
}
```

### Normalisation des Colonnes

**Avant** :
- Un seul format de colonnes attendu
- Erreur si colonnes diff√©rentes

**Apr√®s** :
- Mapping intelligent des variantes
- Gestion des colonnes manquantes
- Compatibilit√© avec tous les formats du dataset

### Chargement Robuste

**Avant** :
- Un seul dataset
- Erreur si dataset non trouv√©

**Apr√®s** :
- Recherche de tous les datasets
- Combinaison automatique
- Continue m√™me si un dataset √©choue
- Logs d√©taill√©s

## Tests Recommand√©s

1. **Test de configuration** :
   - Configurer Watsonx
   - Tester la connexion
   - Lister les datasets

2. **Test de chargement** :
   - V√©rifier que tous les datasets sont charg√©s
   - V√©rifier les logs dans la console

3. **Test de normalisation** :
   - V√©rifier que les colonnes sont bien normalis√©es
   - V√©rifier que les donn√©es sont correctes

4. **Test des visualisations** :
   - V√©rifier les graphiques
   - V√©rifier les comparaisons
   - V√©rifier les filtres

## Prochaines Am√©liorations Possibles

1. **S√©lection manuelle de datasets** :
   - Permettre de choisir quels datasets charger
   - Checkbox pour chaque dataset

2. **Cache des donn√©es** :
   - Mettre en cache les donn√©es charg√©es
   - √âviter de recharger √† chaque fois

3. **Gestion des erreurs am√©lior√©e** :
   - Interface pour voir les datasets qui ont √©chou√©
   - Suggestions de correction

4. **Export par dataset** :
   - Exporter les donn√©es par dataset source
   - Comparer les datasets individuellement

---

**Note** : Le syst√®me est maintenant compatible avec la structure r√©elle du dataset Hugging Face, qui contient plusieurs fichiers CSV avec des configurations diff√©rentes.

